Effects of speech Alignment
Communication plays a vital role in imparting information by speaking, reading or writing
through various mediums. Speaking is considered as one of the most common media to exchange the
ideas, thoughts etc. The advancement of technology has enabled us to communicate with machines
where spoken interaction is considered as an important aspect. Entrainment in spoken dialogue is
commonly defined as a tendency of a speaker to adapt some properties of his speech to match his
interlocutors. It plays an important role in spoken dialogue interaction between human-human and
human-machine interaction. Recent research shows the positive outcome of entrainment (alignment,
accommodation) on various social dimensions such as likeability, learning gains, mutual trust or task
success which all lead to better communication.
The overall goal of this project is to study how alignment can be useful in human-human and
human-machine interactions to build the trust or influence emotional state and affect the decision
making. Social information in speech is carried by the prosody and signaled by changes in the
intonation, loudness, rhythm, and tone-of-voice of the speaker. Acoustic/prosodic (a/p) features in a
speech signal comprises of fundamental frequency (f0), intensity, pitch and speaking rate. When
humans interact with each other these a/p features are adjusted over the course of their conversation.
While entrainment has been explored extensively in human-human interactions, it is less clear how
entrainment can be designed in a human-machine interaction such that the machine entrainment
positively influences social engagement. Therefore, I pose the following two research questions:
(Q1) What acoustic-prosodic (a/p) features are useful in enhancing the entrainment?
(Q2) How acoustic-prosodic entrainment can be modeled to build trust or influence
emotional state or decision making?
To answer the above questions, a spontaneous dialogue interactive game will be designed with a
set of rules for turn-by-turn human-human modeling. The number of participants will interact with
each other and play the given game for certain rounds and their voice will be recorded. PRAAT
toolkit can be used to extract the acoustic/prosodic (a/p) features. The given parameters can be
used to generate a machine voice using a speech synthesizer. The comparison of human speech
and machine-generated speech can further be investigated and a/p parameters can be adjusted for
improving the naturalness in synthesized speech.
Directionality plays an important role in approaching the entrainment in human-machine interaction.
Evidence has been found on both the directions where humans entrain to machines and vice-versa.
Earlier studies have shown that a/p features like speech rate or intensity are changed and humans
adjust their prosody automatically to the machine and they are not consciously aware of this. The
next question is:
(Q3) How does a human adapt their acoustic-prosodic features to a machine?
To address the given problem, the previous mentioned game will be used for modeling and
implementing human-human conversation into a human-machine spoken interaction. The

underlying idea here is to make better distinction of a/p features which are changed in human-
machine interaction based on their previous human-human interaction. The same participants will

be recalled for the given experiment. The speech interaction between a player and machine will

rely on Text to speech (TTS) and ASR systems. For base TTS, speech of female/male speech
trained on state-of-the-art synthesizer will be used. The data will be recorded and further will be
analyzed by state-of-the-art statistical modeling methods. This investigation with a comparison of
their previous response may reveal the adjustments in acoustic/prosodic features made in
participant’s earlier responses.
Speech entrainment allows humans to perceive people who entrain to their speaking style as more

socially attractive and likeable and conversations with such partners as more successful. Dis-
entrainment may signal an increase in social distance and a negative attitude towards the interlocutor.

Recent findings suggest, however, that dis-entrainment may also have some positive effects on the
development of conversation. There is another study which suggests that females tend to trust the
machine whose a/p features, i.e mean pitch, intensity or speech rate are locally dis-entraining (i.e.
move in the opposite direction) and vice versa in males. This leads to another research question:
(Q4) How can a machine adapt to human interlocutor’s state and what is the role of
biological sex in this adaptation?
To address the given problem, OPENSMILE toolkit can be used to analyze the emotional
state of a user and later a/p features of user can allow the system to entrain or dis-entrain based on
their dialogue utterance. The participants will be divided in three groups where the system will
entrain with one group comprising of male participant, dis-entrain with second group comprising of
female participant and employ a mixed strategy (entrain and dis-entrain based on OPEN-SMILE)
with the third group. This experiment can provide better understanding on the role of biological sex
in the relationship between prosodic entrainment and interlocutor’s emotional states.
With recent advancement in technology, we can use anthropomorphism and humanoid features to
improve the interaction between robots and humans in much better way. This leads to another
interesting research question:
(Q5) How can the humanoid facial features of a robot affect human-machine entrainment?
To find the answers to the above question, I will set up the previously mentioned game using
human-machine modeling. A Furhat robot will be used to interact with the participant in the given
game. It has the capability to produce facial expressions and lip movements which can further help
us to investigate the entrainment level of user at various stages.
My plan regarding each research question mentioned above is to provide novel results which
will be published in leading conference proceedings and journal papers. The general expected results
of this study are as followed. Firstly, Knowledge of acoustic-prosodic (a/p) features involved in
speech communication. Secondly, Information regarding the capability of speech alignment to affect
the emotional states and decision-making preferences. Lastly, better distinction between machines
and human interlocutor’s can be made.